[ðŸ¤— Tasks: Question Answering](https://www.youtube.com/watch?v=ajPx5LwJD-I)

[0:08](https://www.youtube.com/watch?v=ajPx5LwJD-I&t=8)
![[Pasted image 20221012230525.jpg]]
 Welcome to the Hugging Face [[NLP Tasks]] Series.

[0:16](https://www.youtube.com/watch?v=ajPx5LwJD-I&t=16)
![[Pasted image 20221012230535.jpg]]
Question answering is the task of finding an answer in a given document.

[0:38](https://www.youtube.com/watch?v=ajPx5LwJD-I&t=38)
![[Pasted image 20221012230540.jpg]]
Question answering is when a model takes a context, or the document you want to search in, and finds an answer within that context. This is also called extractive question answering.

[0:44](https://www.youtube.com/watch?v=ajPx5LwJD-I&t=44)
![[Pasted image 20221012230545.jpg]]
The task is evaluated on two metrics, an exact match, and a fun score. Exact match measures how well the system understands the user's input, while the fun score measures how engaging the system is to use.

[1:15](https://www.youtube.com/watch?v=ajPx5LwJD-I&t=75)
![[Pasted image 20221012230550.jpg]]
The F1 score is a metric used to measure the performance of a classification model. It is calculated as the average of two other metrics, precision and recall. Precision measures the percentage of items that were correctly classified, while recall measures the percentage of items that were classified correctly out of all the items that should have been classified correctly.

[1:36](https://www.youtube.com/watch?v=ajPx5LwJD-I&t=96)
![[Pasted image 20221012230640.jpg]]
You can use question-answering models to automatically answer the questions asked by your customers. You simply need a document containing the information about your business and query through that document with the questions asked by your customers.

[1:57](https://www.youtube.com/watch?v=ajPx5LwJD-I&t=117)![[Pasted image 20221012230644.jpg]]

hf.co/course


